{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from models import ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_loaders, test_loader = utils.get_data_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<torch.cuda.device object at 0x7fd5c5eda390>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#net = ResNet.ResNet18()\n",
    "net = ResNet.ResNet50()\n",
    "#net = ResNet.ResNet152()\n",
    "\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla K80\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    net = net.cuda()\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "else:\n",
    "    print('CPU')\n",
    "    criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "#scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "#scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 32)\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[81, 122], gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = {'train': 4000,'val': 1000,'test': 1000}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = './trained-models/resnet50-net.pth'\n",
    "\n",
    "if old:\n",
    "    old_epochs = utils.load_checkpoint(net, optimizer, scheduler, SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement SWATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print(str(epoch) + \"/\" + str(num_epochs))\n",
    "        \n",
    "        if type(scheduler) is torch.optim.lr_scheduler.MultiStepLR:\n",
    "            scheduler.step()\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            \n",
    "            print(phase)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                \n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            total = 0\n",
    "            \n",
    "            start = time.time()\n",
    "            \n",
    "            for index, (inputs, targets) in enumerate(data_loaders[phase]):\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = outputs.max(1)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                running_loss += loss.item()\n",
    "                running_corrects += preds.eq(targets).sum().item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            epoch_loss = running_loss / total\n",
    "            epoch_acc = running_corrects / total\n",
    "                \n",
    "            print('Loss: ' + str(epoch_loss) + \", Epoch Accuracy: \" + str(epoch_acc))\n",
    "            \n",
    "            print('Time: ' + str((time.time() - start) / 60))\n",
    "            \n",
    "            if phase == 'val' and type(scheduler) is torch.optim.lr_scheduler.ReduceLROnPlateau:\n",
    "                scheduler.step(epoch_loss)\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_accuracy:\n",
    "                best_accuracy = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "                if not os.path.isdir('trained-models'):\n",
    "                    os.mkdir('trained-models')\n",
    "                \n",
    "                state = {\n",
    "                    \n",
    "                    'epoch': epoch,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'scheduler': scheduler.state_dict()\n",
    "                    \n",
    "                }\n",
    "\n",
    "                if os.path.exists(SAVE_PATH):\n",
    "                    os.remove(SAVE_PATH)\n",
    "                \n",
    "                torch.save(state, SAVE_PATH)\n",
    "    \n",
    "    print('Best Accuracy: ' + str(best_accuracy))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "0/200\n",
      "train\n",
      "Loss: 0.1774344204083085, Epoch Accuracy: 0.332475\n",
      "Time: 8.053499134381612\n",
      "val\n",
      "Loss: 0.1392613341510296, Epoch Accuracy: 0.4734\n",
      "Time: 0.5503010431925456\n",
      "1/200\n",
      "train\n",
      "Loss: 0.13380854953676463, Epoch Accuracy: 0.51365\n",
      "Time: 8.113314584891002\n",
      "val\n",
      "Loss: 0.11063577057421208, Epoch Accuracy: 0.5941\n",
      "Time: 0.5501384417215983\n",
      "2/200\n",
      "train\n",
      "Loss: 0.11051312655732036, Epoch Accuracy: 0.6056\n",
      "Time: 8.125343203544617\n",
      "val\n",
      "Loss: 0.08935387621670961, Epoch Accuracy: 0.6771\n",
      "Time: 0.5525282780329387\n",
      "3/200\n",
      "train\n",
      "Loss: 0.0962516548551619, Epoch Accuracy: 0.6601\n",
      "Time: 8.13117868900299\n",
      "val\n",
      "Loss: 0.08174375787973404, Epoch Accuracy: 0.715\n",
      "Time: 0.5507693131764729\n",
      "4/200\n",
      "train\n",
      "Loss: 0.0858205490451306, Epoch Accuracy: 0.700125\n",
      "Time: 8.12622828880946\n",
      "val\n",
      "Loss: 0.07458807299248874, Epoch Accuracy: 0.7411\n",
      "Time: 0.5502122004826864\n",
      "5/200\n",
      "train\n",
      "Loss: 0.07674619561061263, Epoch Accuracy: 0.730525\n",
      "Time: 8.113006242116292\n",
      "val\n",
      "Loss: 0.06851362332180143, Epoch Accuracy: 0.7593\n",
      "Time: 0.5495468179384867\n",
      "6/200\n",
      "train\n",
      "Loss: 0.06977314863353967, Epoch Accuracy: 0.755225\n",
      "Time: 8.116835244496663\n",
      "val\n",
      "Loss: 0.06408410135144368, Epoch Accuracy: 0.7803\n",
      "Time: 0.5527865926424662\n",
      "7/200\n",
      "train\n",
      "Loss: 0.06387260787431151, Epoch Accuracy: 0.777075\n",
      "Time: 8.123983772595723\n",
      "val\n",
      "Loss: 0.05645241468492895, Epoch Accuracy: 0.8069\n",
      "Time: 0.5510228395462036\n",
      "8/200\n",
      "train\n",
      "Loss: 0.05922079649381339, Epoch Accuracy: 0.793175\n",
      "Time: 8.123100980122883\n",
      "val\n",
      "Loss: 0.05275236355457455, Epoch Accuracy: 0.8204\n",
      "Time: 0.5507092714309693\n",
      "9/200\n",
      "train\n",
      "Loss: 0.05451230181057472, Epoch Accuracy: 0.8107\n",
      "Time: 8.135718806584675\n",
      "val\n",
      "Loss: 0.04895011969739571, Epoch Accuracy: 0.8326\n",
      "Time: 0.5503756046295166\n",
      "10/200\n",
      "train\n",
      "Loss: 0.050997959088650534, Epoch Accuracy: 0.823225\n",
      "Time: 8.1174169977506\n",
      "val\n",
      "Loss: 0.04741009935149923, Epoch Accuracy: 0.8407\n",
      "Time: 0.550510823726654\n",
      "11/200\n",
      "train\n",
      "Loss: 0.04746630578893237, Epoch Accuracy: 0.835425\n",
      "Time: 8.122671568393708\n",
      "val\n",
      "Loss: 0.044943620500410904, Epoch Accuracy: 0.8501\n",
      "Time: 0.5526401003201803\n",
      "12/200\n",
      "train\n",
      "Loss: 0.045547860904992556, Epoch Accuracy: 0.83895\n",
      "Time: 8.123684954643249\n",
      "val\n",
      "Loss: 0.04599306394583546, Epoch Accuracy: 0.843\n",
      "Time: 0.5503658254941305\n",
      "13/200\n",
      "train\n",
      "Loss: 0.04229705912907375, Epoch Accuracy: 0.85255\n",
      "Time: 8.12406129837036\n",
      "val\n",
      "Loss: 0.04067794189436827, Epoch Accuracy: 0.8626\n",
      "Time: 0.5515990853309631\n",
      "14/200\n",
      "train\n",
      "Loss: 0.03991601159240818, Epoch Accuracy: 0.860175\n",
      "Time: 8.12575279076894\n",
      "val\n",
      "Loss: 0.03942115063564852, Epoch Accuracy: 0.8672\n",
      "Time: 0.5519267996152242\n",
      "15/200\n",
      "train\n",
      "Loss: 0.03788412415384082, Epoch Accuracy: 0.8672\n",
      "Time: 8.126784181594848\n",
      "val\n",
      "Loss: 0.04022130049481057, Epoch Accuracy: 0.8639\n",
      "Time: 0.5508139212926229\n",
      "16/200\n",
      "train\n",
      "Loss: 0.03602618710474926, Epoch Accuracy: 0.873775\n",
      "Time: 8.125797148545583\n",
      "val\n",
      "Loss: 0.04025606423183344, Epoch Accuracy: 0.8608\n",
      "Time: 0.5500868002573649\n",
      "17/200\n",
      "train\n",
      "Loss: 0.034758788688486676, Epoch Accuracy: 0.87845\n",
      "Time: 8.1201042731603\n",
      "val\n",
      "Loss: 0.03785814047977328, Epoch Accuracy: 0.8748\n",
      "Time: 0.5499581933021546\n",
      "18/200\n",
      "train\n",
      "Loss: 0.0325829538070946, Epoch Accuracy: 0.886025\n",
      "Time: 8.121992027759552\n",
      "val\n",
      "Loss: 0.037036542239000846, Epoch Accuracy: 0.8808\n",
      "Time: 0.5494624336560567\n",
      "19/200\n",
      "train\n",
      "Loss: 0.031486159499577476, Epoch Accuracy: 0.890175\n",
      "Time: 8.123418740431468\n",
      "val\n",
      "Loss: 0.04470012693206081, Epoch Accuracy: 0.8567\n",
      "Time: 0.5500606815020244\n",
      "20/200\n",
      "train\n",
      "Loss: 0.029522647988861717, Epoch Accuracy: 0.897925\n",
      "Time: 8.12454571723938\n",
      "val\n",
      "Loss: 0.03605556366379606, Epoch Accuracy: 0.8802\n",
      "Time: 0.5491568684577942\n",
      "21/200\n",
      "train\n",
      "Loss: 0.02827715217051882, Epoch Accuracy: 0.9007\n",
      "Time: 8.119275442759196\n",
      "val\n",
      "Loss: 0.03856112093131524, Epoch Accuracy: 0.8786\n",
      "Time: 0.5509680072466533\n",
      "22/200\n",
      "train\n",
      "Loss: 0.027218470768499536, Epoch Accuracy: 0.902375\n",
      "Time: 8.121600075562794\n",
      "val\n",
      "Loss: 0.035034087940724566, Epoch Accuracy: 0.8888\n",
      "Time: 0.5513186812400818\n",
      "23/200\n",
      "train\n",
      "Loss: 0.026045614007407857, Epoch Accuracy: 0.909075\n",
      "Time: 8.12002387046814\n",
      "val\n",
      "Loss: 0.03271716923295171, Epoch Accuracy: 0.8927\n",
      "Time: 0.5499054114023845\n",
      "24/200\n",
      "train\n",
      "Loss: 0.024691534825047712, Epoch Accuracy: 0.9124\n",
      "Time: 8.118682912985484\n",
      "val\n",
      "Loss: 0.03414418659166258, Epoch Accuracy: 0.8873\n",
      "Time: 0.5512284318606059\n",
      "25/200\n",
      "train\n",
      "Loss: 0.023712539395145723, Epoch Accuracy: 0.917325\n",
      "Time: 8.122068552176158\n",
      "val\n",
      "Loss: 0.034528079636453185, Epoch Accuracy: 0.8937\n",
      "Time: 0.5496135632197062\n",
      "26/200\n",
      "train\n",
      "Loss: 0.0230029760873731, Epoch Accuracy: 0.91875\n",
      "Time: 8.119003268082936\n",
      "val\n",
      "Loss: 0.03471164049706131, Epoch Accuracy: 0.8911\n",
      "Time: 0.5514248053232829\n",
      "27/200\n",
      "train\n",
      "Loss: 0.022145033108221832, Epoch Accuracy: 0.92125\n",
      "Time: 8.119025731086731\n",
      "val\n",
      "Loss: 0.03302508925872971, Epoch Accuracy: 0.8961\n",
      "Time: 0.5502263307571411\n",
      "28/200\n",
      "train\n",
      "Loss: 0.021002833309573178, Epoch Accuracy: 0.926175\n",
      "Time: 8.131203242142995\n",
      "val\n",
      "Loss: 0.03294169442589864, Epoch Accuracy: 0.8996\n",
      "Time: 0.5520785768826802\n",
      "29/200\n",
      "train\n",
      "Loss: 0.02021051616452496, Epoch Accuracy: 0.92855\n",
      "Time: 8.121068668365478\n",
      "val\n",
      "Loss: 0.03652500762887212, Epoch Accuracy: 0.8936\n",
      "Time: 0.5503446698188782\n",
      "30/200\n",
      "train\n",
      "Loss: 0.019312293593642244, Epoch Accuracy: 0.931825\n",
      "Time: 8.12119038105011\n",
      "val\n",
      "Loss: 0.03519579408493301, Epoch Accuracy: 0.8941\n",
      "Time: 0.5507108370463053\n",
      "31/200\n",
      "train\n",
      "Loss: 0.018767516752124357, Epoch Accuracy: 0.93395\n",
      "Time: 8.120090679327648\n",
      "val\n",
      "Loss: 0.033362334408231255, Epoch Accuracy: 0.8962\n",
      "Time: 0.5530544400215149\n",
      "32/200\n",
      "train\n",
      "Loss: 0.017919668144964818, Epoch Accuracy: 0.9379\n",
      "Time: 8.119011962413788\n",
      "val\n",
      "Loss: 0.031824320731712215, Epoch Accuracy: 0.9057\n",
      "Time: 0.5501673897107442\n",
      "33/200\n",
      "train\n",
      "Loss: 0.017747422359291703, Epoch Accuracy: 0.9365\n",
      "Time: 8.126854519049326\n",
      "val\n",
      "Loss: 0.037166178108520395, Epoch Accuracy: 0.8916\n",
      "Time: 0.5500039696693421\n",
      "34/200\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-278:\n",
      "Process Process-279:\n",
      "Process Process-277:\n",
      "Process Process-280:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-2011b876dc59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-6aff11e9d60c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_epochs = 25\n",
    "\n",
    "if old:\n",
    "    epochs = base_epochs - old_epochs\n",
    "else:\n",
    "    epoch = base_epochs\n",
    "\n",
    "print(epochs)\n",
    "\n",
    "net = train_model(net, criterion, optimizer, scheduler, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10\n",
      "train\n",
      "Loss: 0.010130136712417153, Epoch Accuracy: 0.968025\n",
      "Time: 7.771473491191864\n",
      "val\n",
      "Loss: 0.024848540477099595, Epoch Accuracy: 0.9202\n",
      "Time: 0.5503161509831747\n",
      "1/10\n",
      "train\n",
      "Loss: 0.009947656334062048, Epoch Accuracy: 0.9686\n",
      "Time: 7.778614072004954\n",
      "val\n"
     ]
    }
   ],
   "source": [
    "sgd_epochs = 10\n",
    "utils.load_checkpoint(net, optimizer, scheduler, SAVE_PATH)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.2, weight_decay=5e-4, nesterov=True)\n",
    "net = train_model(net, criterion, optimizer, scheduler, sgd_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
